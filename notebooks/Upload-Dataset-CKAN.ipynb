{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98289df1",
   "metadata": {},
   "source": [
    "# Import a dataset to REALLOCATE CKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8decc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckanapi import RemoteCKAN\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc97a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Step 2: Set up connection and metadata\n",
    "DATASET_NAME = \"walking_trips_1\"\n",
    "LOCATION = \"../data/\"\n",
    "CSV_FILE = f\"{LOCATION}{DATASET_NAME}.csv\"\n",
    "PARQUET_FILE = f\"{LOCATION}{DATASET_NAME}.parquet\"\n",
    "\n",
    "DATASET_TITLE = \"Walking trips\"\n",
    "DATASET_DESCRIPTION = \"Walking trips by year from the EMEF data\"\n",
    "\n",
    "CKAN_URL = \"https://reallocate-ckan.iti.gr\"\n",
    "REALLOCATE_KEY = os.getenv(\"REALLOCATE_KEY\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "ckan = RemoteCKAN(CKAN_URL, apikey=REALLOCATE_KEY)\n",
    "ORG_INFO = ckan.action.organization_show(id=\"bsc\")\n",
    "\n",
    "#Get data\n",
    "API_URL = \"https://portaldades.ajuntament.barcelona.cat/services/backend/rest/statistic/export\"\n",
    "headers = {'X-IBM-Client-Id': API_KEY}\n",
    "DATASETS = {\n",
    "    f'{DATASET_NAME}':'wc9hkmubl7',\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf1a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_dataset(ckan, dataset_name, title=None, notes=\"\", org_id=None):\n",
    "    \"\"\"\n",
    "    Get or create a CKAN dataset by name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset = ckan.action.package_show(id=dataset_name)\n",
    "        print(f\"‚úÖ Dataset '{dataset_name}' already exists.\")\n",
    "    except:\n",
    "        print(f\"‚ÑπÔ∏è Dataset '{dataset_name}' not found. Creating it...\")\n",
    "        create_kwargs = {\n",
    "            \"name\": dataset_name,\n",
    "            \"title\": title or dataset_name,\n",
    "            \"notes\": notes,\n",
    "            \"private\": True\n",
    "        }\n",
    "        if org_id:\n",
    "            create_kwargs[\"owner_org\"] = org_id\n",
    "        dataset = ckan.action.package_create(**create_kwargs)\n",
    "        print(f\"‚úÖ Created dataset '{dataset_name}'.\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d948db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def upload_or_update_resource(ckan, dataset_id, file_path, name, fmt):\n",
    "    \"\"\"\n",
    "    If a resource with this name exists in the dataset, update it.\n",
    "    Otherwise, create a new one.\n",
    "    \"\"\"\n",
    "    # Try to find an existing resource\n",
    "    existing_resource = None\n",
    "    dataset = ckan.action.package_show(id=dataset_id)\n",
    "    for res in dataset[\"resources\"]:\n",
    "        if res[\"name\"] == name:\n",
    "            existing_resource = res\n",
    "            break\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        upload_data = {\n",
    "            \"name\": name,\n",
    "            \"format\": fmt,\n",
    "            \"upload\": f\n",
    "        }\n",
    "\n",
    "        if existing_resource:\n",
    "            # Update existing resource\n",
    "            upload_data[\"id\"] = existing_resource[\"id\"]\n",
    "            res = ckan.action.resource_update(**upload_data)\n",
    "            print(f\"üîÑ Updated existing resource: {res['id']}\")\n",
    "        else:\n",
    "            # Create new resource\n",
    "            upload_data[\"package_id\"] = dataset_id\n",
    "            res = ckan.action.resource_create(**upload_data)\n",
    "            print(f\"‚úÖ Created new resource: {res['id']}\")\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46754c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0730da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Dim-00:TEMPS Dim-01:TERRITORI  Dim-01:TERRITORI (order)  \\\n",
      "0  2015-01-01T00:00:00Z        Barcelona                        -1   \n",
      "1  2015-01-01T00:00:00Z        Barcelona                        -1   \n",
      "2  2016-01-01T00:00:00Z        Barcelona                        -1   \n",
      "3  2016-01-01T00:00:00Z        Barcelona                        -1   \n",
      "4  2017-01-01T00:00:00Z        Barcelona                        -1   \n",
      "\n",
      "  Dim-01:TERRITORI (type) Dim-02:TIPUS DE ETAPA      VALUE  \n",
      "0                Municipi              Connexi√≥    80657.0  \n",
      "1                Municipi               Interna  3280032.0  \n",
      "2                Municipi              Connexi√≥    58655.0  \n",
      "3                Municipi               Interna  2385291.0  \n",
      "4                Municipi               Interna  2287812.0  \n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "DATASET_ID = f\"?id={DATASETS[DATASET_NAME]}&fileformat=CSV\"\n",
    "\n",
    "# Fetch CSV content\n",
    "data_response = requests.get((API_URL + DATASET_ID), headers=headers)\n",
    "\n",
    "# Manually decode with correct encoding\n",
    "decoded_text = data_response.content.decode('utf-8')  # or 'cp1252' if needed\n",
    "\n",
    "# Load into StringIO for pandas\n",
    "csv_file = StringIO(decoded_text)\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb3a75",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "332cae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Step 4 (Optional): Clean your dataset\n",
    "\n",
    "# Example: clean datetime\n",
    "if 'Dim-00:TEMPS' in df.columns:\n",
    "    df['Dim-00:TEMPS'] = pd.to_datetime(df['Dim-00:TEMPS'], errors='coerce') \\\n",
    "                            .dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# Ensure numeric columns are properly parsed\n",
    "for col in df.columns:\n",
    "    if col.upper() == \"VALUE\":\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9691c",
   "metadata": {},
   "source": [
    "## Create/update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dacc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Dataset 'walking_trips_1' not found. Creating it...\n",
      "‚úÖ Created dataset 'walking_trips_1'.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_or_create_dataset(\n",
    "    ckan,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    title=DATASET_TITLE,\n",
    "    notes=DATASET_DESCRIPTION,\n",
    "    org_id=ORG_INFO[\"id\"]  # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce6d3d",
   "metadata": {},
   "source": [
    "## Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72223758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Updated existing resource: 9b629af1-a214-4f8a-b66f-9a38c2803735\n",
      "‚úÖ Created new resource: 0d41b7d1-4b88-4576-967f-70802862ad40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cache_last_updated': None,\n",
       " 'cache_url': None,\n",
       " 'created': '2025-06-25T10:52:14.994161',\n",
       " 'datastore_active': False,\n",
       " 'description': None,\n",
       " 'format': 'Parquet',\n",
       " 'hash': '',\n",
       " 'id': '0d41b7d1-4b88-4576-967f-70802862ad40',\n",
       " 'last_modified': '2025-06-25T10:52:14.978580',\n",
       " 'metadata_modified': '2025-06-25T10:52:14.991998',\n",
       " 'mimetype': None,\n",
       " 'mimetype_inner': None,\n",
       " 'name': 'Walking trips (Parquet)',\n",
       " 'package_id': '4b4b0fe0-6f2a-49a5-bc2a-d7c931ed1eee',\n",
       " 'position': 2,\n",
       " 'resource_type': None,\n",
       " 'size': 4985,\n",
       " 'state': 'active',\n",
       " 'url': 'https://reallocate-ckan.iti.gr:443/dataset/4b4b0fe0-6f2a-49a5-bc2a-d7c931ed1eee/resource/0d41b7d1-4b88-4576-967f-70802862ad40/download/walking_trips_1.parquet',\n",
       " 'url_type': 'upload'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_or_update_resource(\n",
    "    ckan,\n",
    "    dataset_id=dataset[\"id\"],\n",
    "    file_path=CSV_FILE,\n",
    "    name=f\"{DATASET_TITLE} (CSV)\",\n",
    "    fmt=\"CSV\"\n",
    ")\n",
    "\n",
    "upload_or_update_resource(\n",
    "    ckan,\n",
    "    dataset_id=dataset[\"id\"],\n",
    "    file_path=PARQUET_FILE,\n",
    "    name=f\"{DATASET_TITLE} (Parquet)\",\n",
    "    fmt=\"Parquet\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
